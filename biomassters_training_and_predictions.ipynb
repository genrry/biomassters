{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b5455d1",
   "metadata": {},
   "source": [
    "# Biomassters PyTorch Training & Prediction Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf62fa5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83cbf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c43a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec8c909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import Sequential\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchgeo.transforms import indices\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from models import Model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=rasterio.errors.NotGeoreferencedWarning) # biomassters rasters are not georeferenced\n",
    "warnings.filterwarnings('ignore', r'All-NaN (slice|axis) encountered')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feac7e7",
   "metadata": {},
   "source": [
    "#### Local Imports from transforms.py and dataloading.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cf53c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transforms as tf\n",
    "import dataloading as dl\n",
    "from utils import get_tile_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93a9a57",
   "metadata": {},
   "source": [
    "### Setup GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd9d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if torch.backends.mps.is_available(): # Mac M1/M2\n",
    "        device = torch.device('mps')\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        torch.multiprocessing.set_start_method('spawn')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "except AttributeError:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "print(f'training device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c480058",
   "metadata": {},
   "source": [
    "### Set directories for local environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ebd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_tiles = '../data/train_features'\n",
    "dir_target = '../data/train_agbm'\n",
    "dir_test = '../data/test_features'\n",
    "dir_saved_models = './trained_models'\n",
    "\n",
    "bucket_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0395e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful for choosing which bands to keep \n",
    "band_map = {  \n",
    "    # S2 bands\n",
    "    0: 'S2-B2: Blue-10m',\n",
    "    1: 'S2-B3: Green-10m',\n",
    "    2: 'S2-B4: Red-10m',\n",
    "    3: 'S2-B5: VegRed-704nm-20m',\n",
    "    4: 'S2-B6: VegRed-740nm-20m',\n",
    "    5: 'S2-B7: VegRed-780nm-20m',\n",
    "    6: 'S2-B8: NIR-833nm-10m',\n",
    "    7: 'S2-B8A: NarrowNIR-864nm-20m',\n",
    "    8: 'S2-B11: SWIR-1610nm-20m',\n",
    "    9: 'S2-B12: SWIR-2200nm-20m',\n",
    "    10: 'S2-CLP: CloudProb-160m',\n",
    "    # S1 bands\n",
    "    11: 'S1-VV-Asc: Cband-10m',\n",
    "    12: 'S1-VH-Asc: Cband-10m',\n",
    "    13: 'S1-VV-Desc: Cband-10m',\n",
    "    14: 'S1-VH-Desc: Cband-10m',\n",
    "    # Bands derived by transforms \n",
    "    15: 'S2-NDVI: (NIR-Red)/(NIR+Red) 10m',\n",
    "    16: 'S1-NDVVVH-Asc: Norm Diff VV & VH, 10m',\n",
    "    17: 'S2-NDBI: Difference Built-up Index, 20m',\n",
    "    18: 'S2-NDRE: Red Edge Vegetation Index, 20m',\n",
    "    19: 'S2-NDSI: Snow Index, 20m',\n",
    "    20: 'S2-NDWI: Water Index, 10m',\n",
    "    21: 'S2-SWI: Sandardized Water-Level Index, 20m',\n",
    "    22: 'S1-VV/VH-Asc: Cband-10m',\n",
    "    23: 'S2-GNDVI',\n",
    "    24: 'S2-GBNDVI',\n",
    "    25: 'S2-EVI',\n",
    "    26: 'S2-SSAVI',\n",
    "    27: 's2-DPRVI',\n",
    "}\n",
    "month_map = {\n",
    "    0: 'Sep', 1: 'Oct', 2: 'Nov', 3: 'Dec',\n",
    "    4: 'Jan', 5: 'Feb', 6: 'Mar', 7: 'Apr',\n",
    "    8: 'May', 9: 'Jun', 10: 'Jul', 11: 'Aug'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddcd460",
   "metadata": {},
   "source": [
    "### Transforms\n",
    "See https://torchgeo.readthedocs.io/en/latest/tutorials/indices.html and https://torchgeo.readthedocs.io/en/latest/api/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0351b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Sequential(\n",
    "    tf.ClampAGBM(vmin=0., vmax=600.),               # exclude AGBM outliers\n",
    "    tf.AppendNDVI(index_nir=6, index_red=2),        # NDVI, index 15\n",
    "    tf.AppendNormalizedDifferenceIndex(index_a=11, index_b=12), # Radar Vegetation Index (VV-VH)/(VV+VH), index 16\n",
    "    tf.AppendNDBI(index_swir=8, index_nir=6),   # Difference Built-up Index for development detection, index 17\n",
    "    tf.AppendNDRE(index_nir=6, index_vre1=3),   # Red Edge Vegetation Index for canopy detection, index 18\n",
    "    tf.AppendNDSI(index_green=1, index_swir=8), # Snow Index, index 19\n",
    "    tf.AppendNDWI(index_green=1, index_nir=6),  # Difference Water Index for water detection, index 20 \n",
    "    tf.AppendSWI(index_vre1=3, index_swir2=8),  # Standardized Water-Level Index for water detection, index 21\n",
    "    tf.AppendRatioAB(index_a=11, index_b=12),        # VV/VH Ascending, index 22\n",
    "    tf.AppendGNDVI(index_nir=6, index_green=1),  # GNDVI, index 24\n",
    "    tf.AppendGBNDVI(index_nir=6, index_green=1, index_blue=0),  # GBNDVI, index 25\n",
    "    tf.AppendEVI(index_nir=6, index_red=2, index_blue=0), # Enhanced Vegetation Index\n",
    "    tf.AppendSAVI(index_nir=6, index_red=2),         # Soil Adjusted Vegetation Index\n",
    "    tf.AppendDPRVI(index_vh=12, index_vv=11),        # Dual Polarization vegetation index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca201ca",
   "metadata": {},
   "source": [
    "### SentinelDataset - set `max_chips` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e791b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file specifies which month of data to use for training for each chipid \n",
    "# See the preprocesing notebook for an example of producing this  \n",
    "tile_file = 'data/TILE_LIST_BEST_MONTHS.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af66350",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_chips = None # number of chips to use from training set, None = Use All  \n",
    "\n",
    "# A custom dataloader for Sentinel data \n",
    "dataset = dl.SentinelDataset(tile_file=tile_file,\n",
    "                             dir_tiles=dir_tiles,\n",
    "                             dir_target=dir_target,\n",
    "                             max_chips=max_chips,\n",
    "                             transform=transforms,\n",
    "                             device=device,\n",
    "                             gcp_bucket_name=bucket_name,\n",
    "                             scale=False,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33022357",
   "metadata": {},
   "source": [
    "### Split Train/Valid ---Note: manual seed set for reproducibility---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "train_frac = 0.8\n",
    "train_dataset, val_dataset = random_split(dataset, [0.8, 0.2])\n",
    "print(f'N training samples: {len(train_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e45b29",
   "metadata": {},
   "source": [
    "### Dataloaders - set `batch_size` and `num_workers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b045723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12  # Note: training speed is sensitive to memory usage\n",
    "                 # set this as high as you can without significantly slowing down training time \n",
    "num_workers = 0\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=num_workers,\n",
    "                              pin_memory=False\n",
    "                             )\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            num_workers=num_workers,\n",
    "                            pin_memory=False\n",
    "                           )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0789713",
   "metadata": {},
   "source": [
    "### Define some utilities for training\n",
    "* Logger\n",
    "* checkpoints\n",
    "* Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fa7c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_folder = 'training_logs'\n",
    "if not os.path.exists(logs_folder):\n",
    "    os.mkdir(logs_folder)\n",
    "\n",
    "logger = TensorBoardLogger(logs_folder, name='')\n",
    "logs_filepath = os.path.join(logger.save_dir, logger.name, 'version_'+str(logger.version))\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=logs_filepath,\n",
    "    save_top_k=1, \n",
    "    monitor=\"val_loss\",\n",
    "    mode='min',\n",
    "    filename='best_model'\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1dee0d78",
   "metadata": {},
   "source": [
    "### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ba16b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = train_dataset[0]['image'].shape[0]\n",
    "model = Model(in_channels=in_channels)\n",
    "print(f'# input channels: {in_channels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84331ab",
   "metadata": {},
   "source": [
    "### ... Or load a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a8d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_version = 18 # Chhose the experiment version from which to load de model\n",
    "checkpoint_filepath = os.path.join(logger.save_dir, logger.name, 'version_'+str(previous_version))\n",
    "model = model.load_from_checkpoint(os.path.join(checkpoint_filepath,'best_model.ckpt'), in_channels=in_channels)\n",
    "model.train();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffc736ea",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01142e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "trainer = Trainer(\n",
    "    logger=logger,\n",
    "    accelerator=device.type, \n",
    "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "    max_epochs=n_epochs, \n",
    "    devices=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc21d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9639c39c",
   "metadata": {},
   "source": [
    "### Plot RMSE for Training & Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810ab91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir $logs_filepath"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2940bc77",
   "metadata": {},
   "source": [
    "### Load Best model from current experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133291bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.load_from_checkpoint(os.path.join(logs_filepath,'best_model.ckpt'), in_channels=in_channels)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6932f60",
   "metadata": {},
   "source": [
    "## Visualize Sample Predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45df8448",
   "metadata": {},
   "source": [
    "### True AGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "tile_idx = np.random.choice(len(dataset))  # arbitrary tile \n",
    "\n",
    "sample = dataset[tile_idx]\n",
    "\n",
    "plt.imshow(get_tile_image(sample['label'].detach().cpu()),\n",
    "                       interpolation=None,\n",
    "                       norm=LogNorm(clip=True)\n",
    "                       )\n",
    "\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eb76c1",
   "metadata": {},
   "source": [
    "### Predicted AGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13550ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "def predict_agbm(inputs, model):\n",
    "    with torch.no_grad():\n",
    "        if len(inputs.shape)==3:\n",
    "            pred = model(inputs[None,:])\n",
    "        else:\n",
    "            pred = model(inputs)\n",
    "    return pred.detach().squeeze().cpu()\n",
    "\n",
    "plt.imshow(predict_agbm(sample['image'].to(device), model),\n",
    "                       interpolation=None,\n",
    "                       norm=LogNorm(clip=True)\n",
    "                       )\n",
    "\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2065aa",
   "metadata": {},
   "source": [
    "# Process Predictions on Test Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f41ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of best tiles (per chip) for test data \n",
    "tile_file_test = 'data/TILE_LIST_BEST_MONTHS_TEST.csv'\n",
    "\n",
    "# Path to save predictions \n",
    "dir_save_preds = 'data/test_predictions'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210286af",
   "metadata": {},
   "source": [
    "### Define Test Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb26c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_chips = None # number of chips to use, None = Use All  \n",
    "\n",
    "dataset_test = dl.SentinelDataset(tile_file=tile_file_test, # specifies best months of test data \n",
    "                                  dir_tiles=dir_test,       # test data dir\n",
    "                                  dir_target=None,          # No AGBM targets for test data \n",
    "                                  max_chips=max_chips,      \n",
    "                                  transform=transforms,     # same transforms as training\n",
    "                                  device=device,\n",
    "                                  gcp_bucket_name=bucket_name,\n",
    "                                  scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6042196",
   "metadata": {},
   "source": [
    "### Sanity Check: Example Prediction on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9769782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_idx = 0 # arbitrary tile \n",
    "\n",
    "chipid = dataset_test.df_tile_list.iloc[tile_idx]['chipid']\n",
    "inputs = dataset_test[tile_idx]['image'].to(device)\n",
    "agbm = predict_agbm(inputs, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e719b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(agbm)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c59bb8",
   "metadata": {},
   "source": [
    "## Loop through and save all AGBM predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d385a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_agbm(agbm_pred, chipid):\n",
    "    im = Image.fromarray(agbm_pred)\n",
    "    save_path = os.path.join(dir_save_preds, f'{chipid}_agbm.tif')\n",
    "    im.save(save_path, format='TIFF', save_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af01a220",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "for ix, tile in tqdm(enumerate(dataset_test), total=len(dataset_test)):\n",
    "    chipid = dataset_test.df_tile_list.iloc[ix]['chipid']\n",
    "    inputs = tile['image'].to(device)\n",
    "    agbm = predict_agbm(inputs, model).numpy()\n",
    "    save_agbm(agbm, chipid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01843c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create compressed file for submission\n",
    "!tar -cvzf data/test_predictions.tar.gz data/test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c605b1",
   "metadata": {},
   "source": [
    "### Quick Check of Generated Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0956844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(dir_save_preds, f'{chipid}_agbm.tif')\n",
    "test_pred = rasterio.open(file_path).read().astype(np.float32)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa006c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_pred)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomassters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:26:04) [GCC 10.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "bfc3ec9d9e7fd3fb0edb89ac6caff34fa0e021979a0573e03e236ec0facaa48a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
